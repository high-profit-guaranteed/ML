{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 원래 사용하던 numpy 버전 -> 1.26.4 -> 최신버전 tensorflow 지원버전\n",
        "# UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
        "#   warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qww_V4GzhgoS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wC6Rnt6iCxB",
        "outputId": "c36e3725-71c3-43e7-8d50-3f205d2ae363"
      },
      "outputs": [],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\", filename=\"finance_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aP870z3iRc_",
        "outputId": "73de7c41-c9af-4dac-f046-2b4bf1bb4f65"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('finance_data.csv')\n",
        "print('총 샘플의 수 :',len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9eEIdsG4iZYf",
        "outputId": "c8635ca5-186a-4abb-90c6-24abda9cc4c5"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t9XJj_iziaYh",
        "outputId": "19173055-eea0-4749-f08d-442a4231e8f3"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
        "data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNyrW0ynix3O"
      },
      "outputs": [],
      "source": [
        "del data['kor_sentence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5Pz9t4U2i35Q",
        "outputId": "de701957-621f-4af6-f108-bfe7b0bdc793"
      },
      "outputs": [],
      "source": [
        "data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7EW631ui4OA",
        "outputId": "a5cb3abd-20aa-4f1a-efda-918d54c577c6"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkvjJa1Ji7Eo",
        "outputId": "ca02a8a6-96b0-4973-a038-f7f0920e689b"
      },
      "outputs": [],
      "source": [
        "print('결측값 여부 :',data.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoAyW4Lii8xX",
        "outputId": "9122137f-bc5d-44ab-e504-e9419d6ded93"
      },
      "outputs": [],
      "source": [
        "print('sentence 열의 유니크한 값 :',data['sentence'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cks_QRBfjKBU"
      },
      "outputs": [],
      "source": [
        "duplicate = data[data.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "ZwkZ7T0BjL7d",
        "outputId": "b8bb1b19-1a46-4d7b-c34d-dcdc889729f1"
      },
      "outputs": [],
      "source": [
        "duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prnB1Yg5jBt2",
        "outputId": "8e279f29-7a27-463b-ce56-d5e81bbe5b4d"
      },
      "outputs": [],
      "source": [
        "# 중복 제거\n",
        "data.drop_duplicates(subset=['sentence'], inplace=True)\n",
        "print('총 샘플의 수 :',len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "StnulPDqjuKX",
        "outputId": "7dd29a19-678b-4f1f-f51d-2c98faa66c49"
      },
      "outputs": [],
      "source": [
        "data['labels'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP_BFHlojwiN",
        "outputId": "3eb9c43d-af3a-4643-80e0-c4ac4a64bf13"
      },
      "outputs": [],
      "source": [
        "print('레이블의 분포')\n",
        "print(data.groupby('labels').size().reset_index(name='count'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfQdxYqMj3o8",
        "outputId": "e9ec65f4-ce37-49ba-941c-87937b99a830"
      },
      "outputs": [],
      "source": [
        "print(f'중립의 비율 = {round(data[\"labels\"].value_counts()[0]/len(data) * 100,3)}%')\n",
        "print(f'긍정의 비율 = {round(data[\"labels\"].value_counts()[1]/len(data) * 100,3)}%')\n",
        "print(f'부정의 비율 = {round(data[\"labels\"].value_counts()[2]/len(data) * 100,3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jKKmVrDRk46e",
        "outputId": "4e360ed7-24e9-45cd-ccdc-a5a794c24522"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8foVC2rkJtF",
        "outputId": "942ef18e-9b62-4b7b-dc70-ef7175c6c906"
      },
      "outputs": [],
      "source": [
        "X_data = data['sentence']\n",
        "y_data = data['labels']\n",
        "print('본문의 개수: {}'.format(len(X_data)))\n",
        "print('레이블의 개수: {}'.format(len(y_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmFecWmSkHiu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiPJQoBql2T_",
        "outputId": "f7fdc884-0179-4dbe-8904-d2291dfda22d"
      },
      "outputs": [],
      "source": [
        "print('훈련 샘플의 개수 :', len(X_train))\n",
        "print('테스트 샘플의 개수 :', len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-gTg1Z2kYK2",
        "outputId": "c2fdae1d-5d48-47cd-c0c5-df97e191a641"
      },
      "outputs": [],
      "source": [
        "print('--------훈련 데이터의 비율-----------')\n",
        "print(f'중립 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
        "print(f'긍정 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
        "print(f'부정 = {round(y_train.value_counts()[2]/len(y_train) * 100,3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E_XYZIVkcP3",
        "outputId": "83f54be2-aeba-42c3-d0be-6f6447086a32"
      },
      "outputs": [],
      "source": [
        "print('--------테스트 데이터의 비율-----------')\n",
        "print(f'중립 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
        "print(f'긍정 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')\n",
        "print(f'부정 = {round(y_test.value_counts()[2]/len(y_test) * 100,3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qCRNyvpkjEY",
        "outputId": "9afc543f-0f4a-4b73-887a-853a1b265279"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
        "print(X_train_encoded[:5])\n",
        "print(X_test_encoded[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAXqMlPtkm9d",
        "outputId": "1ac80e3d-5f9a-42d3-9fda-a10f8d75b3f1"
      },
      "outputs": [],
      "source": [
        "word_to_index = tokenizer.word_index\n",
        "vocab_size = len(word_to_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "CVaCLg2glTIo",
        "outputId": "d6eb433b-b22e-4995-dbe4-6d6d1e0e4313"
      },
      "outputs": [],
      "source": [
        "print('본문의 최대 길이 :',max(len(sent) for sent in X_train))\n",
        "print('본문의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(sent) for sent in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZvzv8jClpTF"
      },
      "outputs": [],
      "source": [
        "max_len = 302"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO-ypzo6lmuu"
      },
      "outputs": [],
      "source": [
        "X_train_encoded = pad_sequences(X_train_encoded, maxlen=max_len)\n",
        "X_test_encoded = pad_sequences(X_test_encoded, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3LInCb9lqUZ",
        "outputId": "8d554bd4-3ecd-45bd-ca22-289ff0c463e3"
      },
      "outputs": [],
      "source": [
        "X_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_encoded[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRNfINkFlxHI",
        "outputId": "b79a5915-d79a-4896-a246-5dd3946408ca"
      },
      "outputs": [],
      "source": [
        "X_test_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR9qe8oUlyKo"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.models import load_model\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG8mNRPqmRb1"
      },
      "outputs": [],
      "source": [
        "# y_train = to_categorical(y_train)\n",
        "# y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcgxpi4zmWHd",
        "outputId": "7aad670a-4a59-4788-9cff-f4f33fa8d825"
      },
      "outputs": [],
      "source": [
        "# embedding_dim = 64\n",
        "# hidden_units = 64\n",
        "# num_classes = 3\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_size, embedding_dim))\n",
        "# model.add(LSTM(hidden_units))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "# mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "# history = model.fit(X_train_encoded, y_train, epochs=15, callbacks=[es, mc], batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtj0EMOEmeEX",
        "outputId": "98c90e50-a33e-42ef-e056-91bdfb66a088"
      },
      "outputs": [],
      "source": [
        "# loaded_model = load_model('best_model.h5')\n",
        "# print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test_encoded, y_test)[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(X_train_encoded), torch.from_numpy(y_train.values))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_test_encoded), torch.from_numpy(y_test.values))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 32\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "next(iter(train_loader))[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "next(iter(train_loader))[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_size = 64\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 설정값\n",
        "# data_dim = 5\n",
        "# hidden_dim = 10 \n",
        "# output_dim = 1 \n",
        "# learning_rate = 0.01\n",
        "# nb_epochs = 100\n",
        "\n",
        "class myModel(nn.Module):\n",
        "    # # 기본변수, layer를 초기화해주는 생성자\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, num_layers, num_classes):\n",
        "        super(myModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_units, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_units, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        embedded.to(device)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_units).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_units).to(x.device)\n",
        "        out, _ = self.lstm(embedded, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        \n",
        "        return out, h0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # embedding 있음\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class StockNewsLSTM(nn.Module):\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_units, num_layers, num_classes):\n",
        "#         super(StockNewsLSTM, self).__init__()\n",
        "#         self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "#         self.hidden_units = hidden_units\n",
        "#         self.num_layers = num_layers\n",
        "#         self.lstm = nn.LSTM(embedding_dim, hidden_units, num_layers, batch_first=True)\n",
        "#         self.fc = nn.Linear(hidden_units, num_classes)\n",
        "    \n",
        "#     def forward(self, x):\n",
        "#         embedded = self.embedding(x)\n",
        "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_units).to(x.device)\n",
        "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_units).to(x.device)\n",
        "#         out, _ = self.lstm(embedded, (h0, c0))\n",
        "#         out = self.fc(out[:, -1, :])\n",
        "#         return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = myModel(vocab_size, input_size, hidden_size, num_layers, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "train_loss = torch.zeros(epochs)\n",
        "valid_loss = torch.zeros(epochs)\n",
        "\n",
        "train_acc = torch.zeros(epochs)\n",
        "valid_acc = torch.zeros(epochs)\n",
        "\n",
        "for e in tqdm(range(0, epochs)):\n",
        "    model.train()\n",
        "    # initialize hidden state \n",
        "    # h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        output, h = model(inputs)\n",
        "        # calculate the loss and perform backprop\n",
        "        output, h = output.to(device), h.to(device)\n",
        "        loss = criterion(output.squeeze(), labels.long())\n",
        "        loss.backward()\n",
        "        \n",
        "        # calculating accuracy\n",
        "        # accuracy = acc(output,labels)\n",
        "        ps = F.softmax(output, dim=1)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.reshape(top_class.shape)\n",
        "        train_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n",
        "        \n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        # nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "    train_loss[e] /= len(train_loader)\n",
        "    train_acc[e] /= len(train_loader)\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output, val_h = model(inputs, val_h)\n",
        "        output, val_h = output.to(device), val_h.to(device)\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "        ps = F.softmax(output, dim=1)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.reshape(top_class.shape)\n",
        "        valid_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n",
        "    \n",
        "    print(f'Epoch {e+1}') \n",
        "    print(f'train_loss : {train_loss[e]}, val_loss : {valid_loss[e]}')\n",
        "    print(f'train_accuracy : {train_acc[e]*100}, val_accuracy : {valid_acc[e]*100}')\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        torch.save(model, 'model.pth')\n",
        "        torch.save(model.state_dict(), 'model_state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "        valid_loss_min = valid_loss\n",
        "    print(25*'==')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "LSTM finance sentiment analysis_eng.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
